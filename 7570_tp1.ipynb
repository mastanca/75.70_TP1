{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7570_tp1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "hU-1CMXL28eU"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqqtB2Gf2-Jt",
        "colab_type": "text"
      },
      "source": [
        "# 75.70 Trabajo Práctico 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZiEirDh0OGU",
        "colab_type": "text"
      },
      "source": [
        "## Imports y seteo de semillas para randoms\n",
        "\n",
        "Se importan numpy, tensorflow, keras y sklearn. \n",
        "\n",
        "Se setean las semillas de randoms de numpy y tensorflow para tener consistencia entre corridas.\n",
        "\n",
        "Seteamos constante con ubicacion del .csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdkGIgI61OBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(91218) # Set np seed for consistent results across runs\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(91218)\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "CSVPATH = '/content/Admission_Predict_Ver1.1.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5BHdOE51U46",
        "colab_type": "text"
      },
      "source": [
        "## Extracción y procesamiento de datos\n",
        "\n",
        "Se definen las funciones para extracción y procesamiento del set de datos.\n",
        "\n",
        "Se descarta la columna de IDs y se normalizan el resto de las columnas. No se encontraron registros nulos\n",
        "\n",
        "Creamos función para categorizar los datos de entrada segun la salida que tienen (para la segunda red)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxe2ve6X1w2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorize_admition(chance):\n",
        "  if chance < 0.5:\n",
        "    return 0 #'very_bad'\n",
        "  elif chance < 0.65:\n",
        "    return 1 #'bad'\n",
        "  elif chance < 0.8:\n",
        "    return 2 #'medium'\n",
        "  elif chance < 0.9:\n",
        "    return 3 #'good'\n",
        "  else:\n",
        "    return 4 #'very_good'\n",
        "\n",
        "  \n",
        "def process_row(row, categorize=False):\n",
        "  return [\n",
        "      float(row[1])/340.0,\n",
        "      float(row[2])/120.0,\n",
        "      float(row[3])/5.0,\n",
        "      float(row[4])/5.0,\n",
        "      float(row[5])/5.0,\n",
        "      float(row[6])/10.0,\n",
        "      float(row[7]),\n",
        "      categorize_admition(float(row[8])) if categorize else float(row[8])\n",
        "  ]\n",
        "  \n",
        "\n",
        "def extract_data(csvfile, categorize):\n",
        "  rows = csvfile.read().splitlines()\n",
        "  \n",
        "  # Remove headaer and parse rows\n",
        "  rows = rows[1:]\n",
        "  data = [row.split(',') for row in rows]\n",
        "  data = [process_row(row, categorize) for row in data]\n",
        "  \n",
        "  return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU-1CMXL28eU",
        "colab_type": "text"
      },
      "source": [
        "## Formas de entrenamiento\n",
        "\n",
        "Definimos funciones para entrenar. Puede ser utilizando los primeros n elementos del set, utilizando elementos random o los n primeros elementos usando categorias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGh7ELkI3cRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fixed_train(x, y):\n",
        "  max_x = int(len(x) * 0.67) # 33% used for test\n",
        "  max_y = int(len(y) * 0.67) # 33% used for test\n",
        "  return x[:max_x], x[max_x:], y[:max_y], y[max_y:]\n",
        "\n",
        "\n",
        "def random_train(x, y):\n",
        "  return train_test_split(x, y, test_size=0.33, random_state=43)\n",
        "\n",
        "\n",
        "def categorical_train(x, y):\n",
        "  x_train, x_test, y_train, y_test = fixed_train(x, y)\n",
        "  y_train = keras.utils.to_categorical(y_train, num_classes=5)\n",
        "  y_test = keras.utils.to_categorical(y_test, num_classes=5)\n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J6yS5y35Rfm",
        "colab_type": "text"
      },
      "source": [
        "## Carga de datos\n",
        "\n",
        "Se cargan los datos sin categorizar y categorizados.\n",
        "\n",
        "Se toman las primeras 8 columnas como features y la ultima como output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0CnX4lo535w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csv = open(CSVPATH, 'r')\n",
        "\n",
        "normal_data = extract_data(csv, False)\n",
        "csv.seek(0)\n",
        "\n",
        "categorized_data = extract_data(csv, True)\n",
        "csv.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPeRKQOy6O0u",
        "colab_type": "text"
      },
      "source": [
        "## Entrenamiento de la primera red\n",
        "\n",
        "Se crea la primera red usando datos sin categorizar. Como funcion de loss se utiliza el error cuadrático medio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24OAjDTf6Wcw",
        "colab_type": "code",
        "outputId": "a66239bb-6b77-4d1a-eb9d-889bcf69884a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "dataset = np.array(normal_data)\n",
        "x = dataset[:, 0:7]\n",
        "y = dataset[:, 7]\n",
        "\n",
        "X_train, X_test, y_train, y_test = fixed_train(x, y)\n",
        "\n",
        "\n",
        "model_1 = keras.Sequential([\n",
        "    keras.layers.Dense(1, input_dim=7, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='softmax')\n",
        "])\n",
        "\n",
        "model_1.compile(optimizer='adam', \n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mean_squared_error'])\n",
        "\n",
        "model_1.fit(X_train, y_train, epochs=10, batch_size=50, shuffle=False)\n",
        "print(model_1.summary())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "335/335 [==============================] - 0s 279us/sample - loss: 0.0930 - mean_squared_error: 0.0930\n",
            "Epoch 2/10\n",
            "335/335 [==============================] - 0s 30us/sample - loss: 0.0930 - mean_squared_error: 0.0930\n",
            "Epoch 3/10\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 0.0930 - mean_squared_error: 0.0930\n",
            "Epoch 4/10\n",
            "335/335 [==============================] - 0s 28us/sample - loss: 0.0930 - mean_squared_error: 0.0930\n",
            "Epoch 5/10\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 0.0930 - mean_squared_error: 0.0930\n",
            "Epoch 6/10\n",
            "335/335 [==============================] - 0s 36us/sample - loss: 0.0930 - mean_squared_error: 0.0930\n",
            "Epoch 7/10\n",
            "335/335 [==============================] - 0s 34us/sample - loss: 0.0930 - mean_squared_error: 0.0930\n",
            "Epoch 8/10\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 0.0930 - mean_squared_error: 0.0930\n",
            "Epoch 9/10\n",
            "335/335 [==============================] - 0s 30us/sample - loss: 0.0930 - mean_squared_error: 0.0930\n",
            "Epoch 10/10\n",
            "335/335 [==============================] - 0s 31us/sample - loss: 0.0930 - mean_squared_error: 0.0930\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 1)                 8         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzcwj_CQ6ppn",
        "colab_type": "text"
      },
      "source": [
        "## Ejecución de la primera red\n",
        "\n",
        "Ejecutamos la primera red con los datos no categorizados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE64eUOk6w4L",
        "colab_type": "code",
        "outputId": "245114f6-82ce-4ae4-d7d5-3a6643e10e7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_loss, test_acc = model_1.evaluate(X_test, y_test)\n",
        "\n",
        "print('Mean Squared Error:', round(test_loss, 2))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "165/165 [==============================] - 0s 228us/sample - loss: 0.1060 - mean_squared_error: 0.1060\n",
            "Mean Squared Error: 0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6r8sUJB60gO",
        "colab_type": "text"
      },
      "source": [
        "## Entrenamiento de la segunda red\n",
        "\n",
        "Entrenamos la segunda red usando los datos categorizados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkRbPtWW7FGY",
        "colab_type": "code",
        "outputId": "2b05d165-b216-4694-9c96-9cb3ac2f4377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3508
        }
      },
      "source": [
        "dataset = np.array(categorized_data)\n",
        "x = dataset[:, 0:7]\n",
        "y = dataset[:, 7]\n",
        "\n",
        "X_train, X_test, y_train, y_test = categorical_train(x, y)\n",
        "\n",
        "model_2 = keras.Sequential([\n",
        "    keras.layers.Dense(1, input_dim=7, activation='relu'),\n",
        "    keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model_2.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_2.fit(X_train, y_train, epochs=100, batch_size=100, shuffle=False)\n",
        "#print(model_2.summary())"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "335/335 [==============================] - 0s 1ms/sample - loss: 1.5995 - acc: 0.2925\n",
            "Epoch 2/100\n",
            "335/335 [==============================] - 0s 32us/sample - loss: 1.5971 - acc: 0.3284\n",
            "Epoch 3/100\n",
            "335/335 [==============================] - 0s 26us/sample - loss: 1.5949 - acc: 0.3224\n",
            "Epoch 4/100\n",
            "335/335 [==============================] - 0s 28us/sample - loss: 1.5927 - acc: 0.3224\n",
            "Epoch 5/100\n",
            "335/335 [==============================] - 0s 27us/sample - loss: 1.5905 - acc: 0.3224\n",
            "Epoch 6/100\n",
            "335/335 [==============================] - 0s 27us/sample - loss: 1.5882 - acc: 0.3224\n",
            "Epoch 7/100\n",
            "335/335 [==============================] - 0s 25us/sample - loss: 1.5860 - acc: 0.3194\n",
            "Epoch 8/100\n",
            "335/335 [==============================] - 0s 33us/sample - loss: 1.5838 - acc: 0.3194\n",
            "Epoch 9/100\n",
            "335/335 [==============================] - 0s 33us/sample - loss: 1.5817 - acc: 0.3224\n",
            "Epoch 10/100\n",
            "335/335 [==============================] - 0s 33us/sample - loss: 1.5795 - acc: 0.3224\n",
            "Epoch 11/100\n",
            "335/335 [==============================] - 0s 31us/sample - loss: 1.5774 - acc: 0.3224\n",
            "Epoch 12/100\n",
            "335/335 [==============================] - 0s 26us/sample - loss: 1.5752 - acc: 0.3224\n",
            "Epoch 13/100\n",
            "335/335 [==============================] - 0s 27us/sample - loss: 1.5731 - acc: 0.3224\n",
            "Epoch 14/100\n",
            "335/335 [==============================] - 0s 26us/sample - loss: 1.5710 - acc: 0.3224\n",
            "Epoch 15/100\n",
            "335/335 [==============================] - 0s 27us/sample - loss: 1.5688 - acc: 0.3224\n",
            "Epoch 16/100\n",
            "335/335 [==============================] - 0s 30us/sample - loss: 1.5666 - acc: 0.3224\n",
            "Epoch 17/100\n",
            "335/335 [==============================] - 0s 36us/sample - loss: 1.5645 - acc: 0.3224\n",
            "Epoch 18/100\n",
            "335/335 [==============================] - 0s 27us/sample - loss: 1.5623 - acc: 0.3224\n",
            "Epoch 19/100\n",
            "335/335 [==============================] - 0s 25us/sample - loss: 1.5601 - acc: 0.3224\n",
            "Epoch 20/100\n",
            "335/335 [==============================] - 0s 25us/sample - loss: 1.5580 - acc: 0.3224\n",
            "Epoch 21/100\n",
            "335/335 [==============================] - 0s 30us/sample - loss: 1.5558 - acc: 0.3224\n",
            "Epoch 22/100\n",
            "335/335 [==============================] - 0s 28us/sample - loss: 1.5536 - acc: 0.3224\n",
            "Epoch 23/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.5515 - acc: 0.3224\n",
            "Epoch 24/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.5493 - acc: 0.3224\n",
            "Epoch 25/100\n",
            "335/335 [==============================] - 0s 28us/sample - loss: 1.5472 - acc: 0.3224\n",
            "Epoch 26/100\n",
            "335/335 [==============================] - 0s 34us/sample - loss: 1.5450 - acc: 0.3224\n",
            "Epoch 27/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.5429 - acc: 0.3224\n",
            "Epoch 28/100\n",
            "335/335 [==============================] - 0s 35us/sample - loss: 1.5408 - acc: 0.3224\n",
            "Epoch 29/100\n",
            "335/335 [==============================] - 0s 35us/sample - loss: 1.5386 - acc: 0.3224\n",
            "Epoch 30/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.5365 - acc: 0.3224\n",
            "Epoch 31/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.5344 - acc: 0.3224\n",
            "Epoch 32/100\n",
            "335/335 [==============================] - 0s 32us/sample - loss: 1.5322 - acc: 0.3224\n",
            "Epoch 33/100\n",
            "335/335 [==============================] - 0s 31us/sample - loss: 1.5301 - acc: 0.3224\n",
            "Epoch 34/100\n",
            "335/335 [==============================] - 0s 37us/sample - loss: 1.5280 - acc: 0.3224\n",
            "Epoch 35/100\n",
            "335/335 [==============================] - 0s 32us/sample - loss: 1.5259 - acc: 0.3224\n",
            "Epoch 36/100\n",
            "335/335 [==============================] - 0s 31us/sample - loss: 1.5238 - acc: 0.3224\n",
            "Epoch 37/100\n",
            "335/335 [==============================] - 0s 28us/sample - loss: 1.5217 - acc: 0.3224\n",
            "Epoch 38/100\n",
            "335/335 [==============================] - 0s 27us/sample - loss: 1.5196 - acc: 0.3224\n",
            "Epoch 39/100\n",
            "335/335 [==============================] - 0s 26us/sample - loss: 1.5175 - acc: 0.3224\n",
            "Epoch 40/100\n",
            "335/335 [==============================] - 0s 31us/sample - loss: 1.5154 - acc: 0.3224\n",
            "Epoch 41/100\n",
            "335/335 [==============================] - 0s 25us/sample - loss: 1.5133 - acc: 0.3224\n",
            "Epoch 42/100\n",
            "335/335 [==============================] - 0s 27us/sample - loss: 1.5113 - acc: 0.3224\n",
            "Epoch 43/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.5092 - acc: 0.3194\n",
            "Epoch 44/100\n",
            "335/335 [==============================] - 0s 27us/sample - loss: 1.5072 - acc: 0.3194\n",
            "Epoch 45/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.5051 - acc: 0.3194\n",
            "Epoch 46/100\n",
            "335/335 [==============================] - 0s 32us/sample - loss: 1.5031 - acc: 0.3194\n",
            "Epoch 47/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.5010 - acc: 0.3224\n",
            "Epoch 48/100\n",
            "335/335 [==============================] - 0s 33us/sample - loss: 1.4990 - acc: 0.3254\n",
            "Epoch 49/100\n",
            "335/335 [==============================] - 0s 30us/sample - loss: 1.4970 - acc: 0.3224\n",
            "Epoch 50/100\n",
            "335/335 [==============================] - 0s 31us/sample - loss: 1.4949 - acc: 0.3194\n",
            "Epoch 51/100\n",
            "335/335 [==============================] - 0s 38us/sample - loss: 1.4929 - acc: 0.3194\n",
            "Epoch 52/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.4909 - acc: 0.3194\n",
            "Epoch 53/100\n",
            "335/335 [==============================] - 0s 36us/sample - loss: 1.4889 - acc: 0.3224\n",
            "Epoch 54/100\n",
            "335/335 [==============================] - 0s 26us/sample - loss: 1.4870 - acc: 0.3224\n",
            "Epoch 55/100\n",
            "335/335 [==============================] - 0s 31us/sample - loss: 1.4850 - acc: 0.3284\n",
            "Epoch 56/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.4830 - acc: 0.3284\n",
            "Epoch 57/100\n",
            "335/335 [==============================] - 0s 27us/sample - loss: 1.4811 - acc: 0.3313\n",
            "Epoch 58/100\n",
            "335/335 [==============================] - 0s 33us/sample - loss: 1.4791 - acc: 0.3343\n",
            "Epoch 59/100\n",
            "335/335 [==============================] - 0s 31us/sample - loss: 1.4772 - acc: 0.3343\n",
            "Epoch 60/100\n",
            "335/335 [==============================] - 0s 30us/sample - loss: 1.4753 - acc: 0.3343\n",
            "Epoch 61/100\n",
            "335/335 [==============================] - 0s 31us/sample - loss: 1.4733 - acc: 0.3284\n",
            "Epoch 62/100\n",
            "335/335 [==============================] - 0s 26us/sample - loss: 1.4714 - acc: 0.3313\n",
            "Epoch 63/100\n",
            "335/335 [==============================] - 0s 27us/sample - loss: 1.4695 - acc: 0.3343\n",
            "Epoch 64/100\n",
            "335/335 [==============================] - 0s 31us/sample - loss: 1.4676 - acc: 0.3313\n",
            "Epoch 65/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.4658 - acc: 0.3313\n",
            "Epoch 66/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.4639 - acc: 0.3284\n",
            "Epoch 67/100\n",
            "335/335 [==============================] - 0s 28us/sample - loss: 1.4621 - acc: 0.3284\n",
            "Epoch 68/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.4602 - acc: 0.3313\n",
            "Epoch 69/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.4584 - acc: 0.3343\n",
            "Epoch 70/100\n",
            "335/335 [==============================] - 0s 43us/sample - loss: 1.4566 - acc: 0.3343\n",
            "Epoch 71/100\n",
            "335/335 [==============================] - 0s 32us/sample - loss: 1.4548 - acc: 0.3403\n",
            "Epoch 72/100\n",
            "335/335 [==============================] - 0s 32us/sample - loss: 1.4530 - acc: 0.3373\n",
            "Epoch 73/100\n",
            "335/335 [==============================] - 0s 34us/sample - loss: 1.4512 - acc: 0.3373\n",
            "Epoch 74/100\n",
            "335/335 [==============================] - 0s 31us/sample - loss: 1.4494 - acc: 0.3433\n",
            "Epoch 75/100\n",
            "335/335 [==============================] - 0s 36us/sample - loss: 1.4477 - acc: 0.3403\n",
            "Epoch 76/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.4459 - acc: 0.3403\n",
            "Epoch 77/100\n",
            "335/335 [==============================] - 0s 31us/sample - loss: 1.4442 - acc: 0.3403\n",
            "Epoch 78/100\n",
            "335/335 [==============================] - 0s 35us/sample - loss: 1.4425 - acc: 0.3373\n",
            "Epoch 79/100\n",
            "335/335 [==============================] - 0s 28us/sample - loss: 1.4408 - acc: 0.3403\n",
            "Epoch 80/100\n",
            "335/335 [==============================] - 0s 28us/sample - loss: 1.4391 - acc: 0.3343\n",
            "Epoch 81/100\n",
            "335/335 [==============================] - 0s 33us/sample - loss: 1.4374 - acc: 0.3373\n",
            "Epoch 82/100\n",
            "335/335 [==============================] - 0s 34us/sample - loss: 1.4358 - acc: 0.3433\n",
            "Epoch 83/100\n",
            "335/335 [==============================] - 0s 34us/sample - loss: 1.4341 - acc: 0.3433\n",
            "Epoch 84/100\n",
            "335/335 [==============================] - 0s 42us/sample - loss: 1.4325 - acc: 0.3433\n",
            "Epoch 85/100\n",
            "335/335 [==============================] - 0s 28us/sample - loss: 1.4309 - acc: 0.3343\n",
            "Epoch 86/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.4293 - acc: 0.3403\n",
            "Epoch 87/100\n",
            "335/335 [==============================] - 0s 30us/sample - loss: 1.4277 - acc: 0.3373\n",
            "Epoch 88/100\n",
            "335/335 [==============================] - 0s 28us/sample - loss: 1.4261 - acc: 0.3403\n",
            "Epoch 89/100\n",
            "335/335 [==============================] - 0s 33us/sample - loss: 1.4245 - acc: 0.3373\n",
            "Epoch 90/100\n",
            "335/335 [==============================] - 0s 33us/sample - loss: 1.4230 - acc: 0.3373\n",
            "Epoch 91/100\n",
            "335/335 [==============================] - 0s 34us/sample - loss: 1.4215 - acc: 0.3373\n",
            "Epoch 92/100\n",
            "335/335 [==============================] - 0s 34us/sample - loss: 1.4199 - acc: 0.3403\n",
            "Epoch 93/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.4184 - acc: 0.3433\n",
            "Epoch 94/100\n",
            "335/335 [==============================] - 0s 35us/sample - loss: 1.4170 - acc: 0.3433\n",
            "Epoch 95/100\n",
            "335/335 [==============================] - 0s 30us/sample - loss: 1.4155 - acc: 0.3522\n",
            "Epoch 96/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.4140 - acc: 0.3522\n",
            "Epoch 97/100\n",
            "335/335 [==============================] - 0s 29us/sample - loss: 1.4126 - acc: 0.3522\n",
            "Epoch 98/100\n",
            "335/335 [==============================] - 0s 32us/sample - loss: 1.4112 - acc: 0.3612\n",
            "Epoch 99/100\n",
            "335/335 [==============================] - 0s 30us/sample - loss: 1.4098 - acc: 0.3612\n",
            "Epoch 100/100\n",
            "335/335 [==============================] - 0s 39us/sample - loss: 1.4084 - acc: 0.3672\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f098fd0ebe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEjjCRsp7LRN",
        "colab_type": "text"
      },
      "source": [
        "## Ejecución de la segunda red\n",
        "\n",
        "Ejecutamos la segunda red, usando los datos categorizados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK-bF9rT7RdL",
        "colab_type": "code",
        "outputId": "0ff4116a-b400-4094-fe77-26e95bd526cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_loss, test_acc = model_2.evaluate(X_test, y_test)\n",
        "\n",
        "print('Test accuracy:', round(test_acc*100, 2), '%')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "165/165 [==============================] - 0s 2ms/sample - loss: 1.4111 - acc: 0.4061\n",
            "Test accuracy: 40.61 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}